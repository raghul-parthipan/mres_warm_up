{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from pandarallel import pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Examination and Preparation #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('GTEX_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sorted_id = dataset.sort_values(by=['Unnamed: 0'])\n",
    "del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset is sorted so that the test and training set won't have the same person's entries in each, in order to prevent data leakage. \n",
    "\n",
    "Note that this method is not perfect and will allow one person's entries to appear in both test and training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_sorted_id.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No NANs in dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non stratified split method\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "#label encode targets\n",
    "le = LabelEncoder()\n",
    "dataset_sorted_id[\"tissue\"] = le.fit_transform(dataset_sorted_id[\"tissue\"])\n",
    "\n",
    "#split up, and use if statement to ensure patients don't appear in different sets\n",
    "train_full, test = train_test_split(dataset_sorted_id, test_size=0.2, shuffle=False)\n",
    "if train_full['Unnamed: 0'].iloc[-1] == test['Unnamed: 0'].iloc[0]:\n",
    "    rows = test.loc[test['Unnamed: 0'] == test['Unnamed: 0'].iloc[0]]\n",
    "    train_full = train_full.append(rows, ignore_index=True)\n",
    "    test.drop(rows.index, inplace=True)\n",
    "    \n",
    "    \n",
    "train, val = train_test_split(train_full, test_size=0.2, shuffle=False)\n",
    "if train['Unnamed: 0'].iloc[-1] == val['Unnamed: 0'].iloc[0]:\n",
    "    rows = val.loc[val['Unnamed: 0'] == val['Unnamed: 0'].iloc[0]]\n",
    "    train = train.append(rows, ignore_index=True)\n",
    "    val.drop(rows.index, inplace=True)\n",
    "\n",
    "\n",
    "X_train = train.drop([\"tissue\", \"Unnamed: 0\"], axis=1)\n",
    "X_test = test.drop([\"tissue\", \"Unnamed: 0\"], axis=1)\n",
    "X_val = val.drop([\"tissue\", \"Unnamed: 0\"], axis=1)\n",
    "\n",
    "y_train = (train[\"tissue\"])\n",
    "y_test = (test[\"tissue\"])\n",
    "y_val = (val[\"tissue\"])\n",
    "\n",
    "#scale all features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "del train_full, test, train, val, X_train, X_test, X_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratified split method with enforcing of patients not being in different classes\n",
    "\n",
    "#below stratifies by tissue by making new column \"tr\" and labelling True if that row should be in the train set\n",
    "for tissue in dataset_sorted_id[\"tissue\"].unique():\n",
    "    row_nums = dataset_sorted_id[dataset_sorted_id[\"tissue\"]==tissue].index\n",
    "    all_cat_idx = np.array(row_nums)\n",
    "    n_tr = np.ceil(len(row_nums)*0.8)\n",
    "    indices = np.random.choice(all_cat_idx, int(n_tr), replace=False)\n",
    "    dataset_sorted_id.loc[indices, \"tr\"] = True\n",
    "    \n",
    "dataset_sorted_id.loc[dataset_sorted_id[\"tr\"] != True, \"tr\"] = False\n",
    "\n",
    "#below code finds the unique patients in tr and the unique ones in te\n",
    "tr_patients = np.array(dataset_sorted_id.loc[dataset_sorted_id['tr'] == True, 'Unnamed: 0'].unique())\n",
    "te_patients = np.array(dataset_sorted_id.loc[dataset_sorted_id['tr'] == False, 'Unnamed: 0'].unique())\n",
    "\n",
    "intersection = list(set(tr_patients) & set(te_patients))\n",
    "#the intersection is of size 792. There are 838 patients in total. We would then have to randomly move 80% of these 792 patients\n",
    "#train set and 20% to test set. We would basically lose our formal stratification then. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = len(le.classes_)\n",
    "number_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check stratification ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_stratification(subset1, subset2, dataset=dataset):\n",
    "    \"\"\"A function to compare the stratification in two subsets of the dataset (i.e. test and val) to that in the whole dataset.\n",
    "    Dataset is the whole dataset.\n",
    "    Subset are subsets, which are here are Series since we will be passing in the features 'y' as we want \n",
    "    stratification on the tissues.\n",
    "    Creates a table showing the % difference in stratification\"\"\"\n",
    "    \n",
    "    def tissue_proportions(data):\n",
    "        return data[\"tissue\"].value_counts()/len(data)\n",
    "    \n",
    "    def tissue_proportions_sub(data):\n",
    "        return data.value_counts()/len(data)\n",
    "    \n",
    "    compare_props = pd.DataFrame({\n",
    "        \"Overall\": tissue_proportions(dataset),\n",
    "        \"Subset1\": tissue_proportions_sub(subset1),\n",
    "        \"Subset2\": tissue_proportions_sub(subset2),\n",
    "            }).sort_values(by='Overall', ascending=False)\n",
    "    compare_props[\"subset1. %error\"] = 100 * tissue_proportions_sub(subset1)/ tissue_proportions(dataset) - 100\n",
    "    compare_props[\"subset2. %error\"] = 100 * tissue_proportions_sub(subset2) / tissue_proportions(dataset) - 100\n",
    "    \n",
    "    return compare_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_stratification(subset1=y_test, subset2=y_val, dataset=dataset_sorted_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Exploration #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can fit to training set. Poor result on test set -> overfitting. Can examine with hyperparameter tuning later.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result is 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_grid = {\n",
    "\n",
    "  'n_estimators': sp_randint(200,600),\n",
    "  'max_depth':  sp_randint(20,110),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search = RandomForestClassifier(n_jobs=-1, verbose=3)\n",
    "random_search_rf = RandomizedSearchCV(rnd_search, parameter_grid, cv=KFold(n_splits=3, shuffle=False), random_state=42, verbose=3, n_iter=5)\n",
    "\n",
    "random_search_rf.fit(X_train_scaled,y_train)\n",
    "\n",
    "result = pd.concat([pd.DataFrame(random_search_rf.cv_results_[\"params\"]),pd.DataFrame(random_search_rf.cv_results_[\"mean_test_score\"], columns=[\"Score\"])],axis=1)\n",
    "result.sort_values(by=\"Score\", ascending=False, inplace=True)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best score is around 0.57. So RF can overfit well, but struggling to generalise. Would need more estimators for a better score but it doesn't look to be as promising as the NN. Why? I thought RF should be comparable given it is tabular data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf= RandomForestClassifier(n_jobs=-1, verbose=3, max_depth=71, n_estimators=548)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_val_scaled, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and val scores are not too disimilar (unlike NN) -> maybe NN just performs far better on val set - val set is different in composition to test set after all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only testing on one validation set is not robust right? You could do some sort of cross validation where you select different validation folds, but then training is just longer. I guess it depends on the size of the validation fold. But what is done in practice? -> just one val set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_valid, X_train = X_val_scaled, X_train_scaled\n",
    "y_valid, y_train = y_val, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(1000, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(500, activation=\"relu\"),\n",
    "    keras.layers.Dropout(rate = 0.2)\n",
    "    keras.layers.Dense(number_classes, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "\n",
    "#callbacks\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model.h5\", save_best_only=True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=100,\n",
    "                   validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##sample##\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "predictions = model(x_train[:1]).numpy()\n",
    "\n",
    "\n",
    "tf.nn.softmax(predictions).numpy()\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_fn(y_train[:1], predictions).numpy()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
